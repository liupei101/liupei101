<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p><img class="emoji" title=":fire:" alt=":fire:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20" width="20"> Two co-authored papers, <strong>QPMIL-VL</strong> (<a href="https://arxiv.org/pdf/2410.10573" rel="external nofollow noopener" target="_blank">Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification</a>) and <strong>MVOL</strong> (<a href="https://arxiv.org/pdf/2412.11466" rel="external nofollow noopener" target="_blank">Mining In-distribution Attributes in Outliers for Out-of-distribution Detection</a>), are accepted at <a href="https://openreview.net/group?id=AAAI.org/2025/Conference" rel="external nofollow noopener" target="_blank">AAAI 2025</a>. For QPMIL-VL, please check its <a href="https://arxiv.org/pdf/2410.10573" rel="external nofollow noopener" target="_blank">arXiv preprint</a> &amp; <a href="https://github.com/can-can-ya/QPMIL-VL" rel="external nofollow noopener" target="_blank">Code</a>. For MVOL, please check its <a href="https://arxiv.org/pdf/2412.11466" rel="external nofollow noopener" target="_blank">arXiv preprint</a> &amp; <a href="https://github.com/UESTC-nnLab/MVOL" rel="external nofollow noopener" target="_blank">Code</a>.</p> </body></html>